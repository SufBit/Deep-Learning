{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "230d219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e802746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the Fashion MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d389523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to be in the range [0, 1]\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cdfe0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b4e0bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18a60078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Define the CNN architecture\n",
    "model_cnn = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea7e2bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_cnn.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21f1aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the input data for CNN (add a channel dimension)\n",
    "train_images_cnn = train_images.reshape((train_images.shape[0], 28, 28, 1))\n",
    "val_images_cnn = val_images.reshape((val_images.shape[0], 28, 28, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a01a30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.7150 - loss: 0.8106 - val_accuracy: 0.8495 - val_loss: 0.4085\n",
      "Epoch 2/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.8661 - loss: 0.3720 - val_accuracy: 0.8771 - val_loss: 0.3309\n",
      "Epoch 3/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.8866 - loss: 0.3136 - val_accuracy: 0.8898 - val_loss: 0.2982\n",
      "Epoch 4/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9010 - loss: 0.2743 - val_accuracy: 0.8942 - val_loss: 0.2911\n",
      "Epoch 5/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9103 - loss: 0.2486 - val_accuracy: 0.8987 - val_loss: 0.2772\n",
      "Epoch 6/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9184 - loss: 0.2233 - val_accuracy: 0.8951 - val_loss: 0.2862\n",
      "Epoch 7/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9258 - loss: 0.2065 - val_accuracy: 0.9053 - val_loss: 0.2580\n",
      "Epoch 8/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9311 - loss: 0.1852 - val_accuracy: 0.9038 - val_loss: 0.2620\n",
      "Epoch 9/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9364 - loss: 0.1707 - val_accuracy: 0.9043 - val_loss: 0.2645\n",
      "Epoch 10/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9409 - loss: 0.1578 - val_accuracy: 0.9120 - val_loss: 0.2542\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history_cnn = model_cnn.fit(train_images_cnn, train_labels, epochs=10, batch_size=64,\n",
    "                             validation_data=(val_images_cnn, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2be7de55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2482\n",
      "Validation accuracy: 0.9120000004768372\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on validation data\n",
    "val_loss, val_acc = model_cnn.evaluate(val_images_cnn, val_labels)\n",
    "print(\"Validation accuracy:\", val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1e82900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the test data\n",
    "test_images_cnn = test_images.reshape((test_images.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25cb884a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9018 - loss: 0.2820\n",
      "Test accuracy: 0.9039999842643738\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = model_cnn.evaluate(test_images_cnn, test_labels)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d72c378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DNN architecture\n",
    "model_dnn = models.Sequential([\n",
    "    layers.Input(shape=(28, 28)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ea13953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the DNN model\n",
    "model_dnn.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a0d48c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7023 - loss: 0.8469 - val_accuracy: 0.8462 - val_loss: 0.4300\n",
      "Epoch 2/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 943us/step - accuracy: 0.8388 - loss: 0.4513 - val_accuracy: 0.8595 - val_loss: 0.3907\n",
      "Epoch 3/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 0.8546 - loss: 0.4076 - val_accuracy: 0.8637 - val_loss: 0.3669\n",
      "Epoch 4/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8618 - loss: 0.3808 - val_accuracy: 0.8697 - val_loss: 0.3576\n",
      "Epoch 5/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 997us/step - accuracy: 0.8709 - loss: 0.3575 - val_accuracy: 0.8750 - val_loss: 0.3463\n",
      "Epoch 6/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982us/step - accuracy: 0.8726 - loss: 0.3464 - val_accuracy: 0.8777 - val_loss: 0.3302\n",
      "Epoch 7/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934us/step - accuracy: 0.8798 - loss: 0.3332 - val_accuracy: 0.8765 - val_loss: 0.3459\n",
      "Epoch 8/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - accuracy: 0.8815 - loss: 0.3265 - val_accuracy: 0.8778 - val_loss: 0.3247\n",
      "Epoch 9/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - accuracy: 0.8875 - loss: 0.3075 - val_accuracy: 0.8813 - val_loss: 0.3237\n",
      "Epoch 10/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 0.8877 - loss: 0.3005 - val_accuracy: 0.8838 - val_loss: 0.3202\n"
     ]
    }
   ],
   "source": [
    "# Train the DNN model\n",
    "history_dnn = model_dnn.fit(train_images, train_labels, epochs=10, batch_size=64,\n",
    "                             validation_data=(val_images, val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5701cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step - accuracy: 0.8862 - loss: 0.3210\n",
      "Validation accuracy (DNN): 0.8837500214576721\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the DNN model on validation data\n",
    "val_loss_dnn, val_acc_dnn = model_dnn.evaluate(val_images, val_labels)\n",
    "print(\"Validation accuracy (DNN):\", val_acc_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b870700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step - accuracy: 0.8793 - loss: 0.3455\n",
      "Test accuracy (DNN): 0.8777999877929688\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the DNN model on test data\n",
    "test_loss_dnn, test_acc_dnn = model_dnn.evaluate(test_images, test_labels)\n",
    "print(\"Test accuracy (DNN):\", test_acc_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "509446a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MLP architecture\n",
    "model_mlp = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abe9ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the MLP model\n",
    "model_mlp.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89f48cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6327 - loss: 1.0226 - val_accuracy: 0.8369 - val_loss: 0.4456\n",
      "Epoch 2/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8260 - loss: 0.4989 - val_accuracy: 0.8544 - val_loss: 0.3912\n",
      "Epoch 3/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.4419 - val_accuracy: 0.8673 - val_loss: 0.3727\n",
      "Epoch 4/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8552 - loss: 0.4119 - val_accuracy: 0.8682 - val_loss: 0.3602\n",
      "Epoch 5/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8601 - loss: 0.3947 - val_accuracy: 0.8641 - val_loss: 0.3765\n",
      "Epoch 6/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8655 - loss: 0.3769 - val_accuracy: 0.8716 - val_loss: 0.3507\n",
      "Epoch 7/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8703 - loss: 0.3643 - val_accuracy: 0.8735 - val_loss: 0.3400\n",
      "Epoch 8/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8678 - loss: 0.3582 - val_accuracy: 0.8760 - val_loss: 0.3327\n",
      "Epoch 9/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8761 - loss: 0.3427 - val_accuracy: 0.8820 - val_loss: 0.3284\n",
      "Epoch 10/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8761 - loss: 0.3432 - val_accuracy: 0.8808 - val_loss: 0.3278\n"
     ]
    }
   ],
   "source": [
    "# Train the MLP model\n",
    "history_mlp = model_mlp.fit(train_images, train_labels, epochs=10, batch_size=64,\n",
    "                             validation_data=(val_images, val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb6f59e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.8815 - loss: 0.3267\n",
      "Validation accuracy (MLP): 0.8807500004768372\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the MLP model on validation data\n",
    "val_loss_mlp, val_acc_mlp = model_mlp.evaluate(val_images, val_labels)\n",
    "print(\"Validation accuracy (MLP):\", val_acc_mlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79120e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.8741 - loss: 0.3505\n",
      "Test accuracy (MLP): 0.8748999834060669\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the MLP model on test data\n",
    "test_loss_mlp, test_acc_mlp = model_mlp.evaluate(test_images, test_labels)\n",
    "print(\"Test accuracy (MLP):\", test_acc_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87126eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As committee\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3de6bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step\n"
     ]
    }
   ],
   "source": [
    "# Get the predicted probabilities for each model on the test data\n",
    "probabilities_cnn = model_cnn.predict(test_images)\n",
    "probabilities_dnn = model_dnn.predict(test_images)\n",
    "probabilities_mlp = model_mlp.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "671104b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average the predicted probabilities across all three models\n",
    "ensemble_probabilities = (probabilities_cnn + probabilities_dnn + probabilities_mlp) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1ea04d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the class predictions by selecting the class with the highest probability\n",
    "ensemble_predictions = np.argmax(ensemble_probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9db333c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy (Ensemble): 0.9045\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the ensemble on the test data\n",
    "test_accuracy_ensemble = np.mean(ensemble_predictions == test_labels)\n",
    "print(\"Test accuracy (Ensemble):\", test_accuracy_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "902be5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Model Accuracies:\n",
      "CNN Model Accuracy: 0.9039999842643738\n",
      "DNN Model Accuracy: 0.8777999877929688\n",
      "MLP Model Accuracy: 0.8748999834060669\n",
      "\n",
      "Final Accuracy of the Committee:\n",
      "Ensemble Model Accuracy: 0.9045\n"
     ]
    }
   ],
   "source": [
    "# Report individual model accuracies\n",
    "print(\"Individual Model Accuracies:\")\n",
    "print(\"CNN Model Accuracy:\", test_acc)\n",
    "print(\"DNN Model Accuracy:\", test_acc_dnn)\n",
    "print(\"MLP Model Accuracy:\", test_acc_mlp)\n",
    "\n",
    "# Report final accuracy of the committee\n",
    "print(\"\\nFinal Accuracy of the Committee:\")\n",
    "print(\"Ensemble Model Accuracy:\", test_accuracy_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0d9dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2A How are the diverse deep-learning models formed in your project, please explain? (10points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e9a0815c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN (Convolutional Neural Network):\n",
      "CNNs tend to be very good in capturing spatial hierarchies in images. In my implmentation of CNNs it consists of convolutional layers followed by max-pooling layers and dense layers. The convulutional layers extract certain features from the images through filters.\n",
      " \n",
      "DNN (Deep Neural Networks):\n",
      "DNNs consist of connected layers and are effective when learning patterns that are complex in data. In my implementation it is a simple feed forward network with multiple hidden layers. Each layer connects with another layer, this allows it to learn relations that are non-linear.\n",
      " \n",
      "MLP (Multi-Layer perceptron):\n",
      "They are feedforward networks with multiple layers of nodes, they can be used for both classification and regression. In my impelmentation it has multiple hidden layers with ReLU activation functions and a softmax output layer for classification.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CNN (Convolutional Neural Network):\")\n",
    "print(\"CNNs tend to be very good in capturing spatial hierarchies in images. In my implmentation of CNNs it consists of convolutional layers followed by max-pooling layers and dense layers. The convulutional layers extract certain features from the images through filters.\\n \")\n",
    "print(\"DNN (Deep Neural Networks):\")\n",
    "print(\"DNNs consist of connected layers and are effective when learning patterns that are complex in data. In my implementation it is a simple feed forward network with multiple hidden layers. Each layer connects with another layer, this allows it to learn relations that are non-linear.\\n \")\n",
    "print(\"MLP (Multi-Layer perceptron):\")\n",
    "print(\"They are feedforward networks with multiple layers of nodes, they can be used for both classification and regression. In my impelmentation it has multiple hidden layers with ReLU activation functions and a softmax output layer for classification.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc06484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2B How are the three diverse deep-learning models combined? (20 points).\n",
    "print(\"Done on Submission PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ee5ab9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step\n",
      "\n",
      "Final Metrics of Individual Models:\n",
      "  Model  Accuracy  CNN Precision  CNN Recall  CNN F1-Score  DNN Precision  \\\n",
      "0   CNN    0.9905       0.906548       0.904       0.90468       0.877663   \n",
      "1   DNN    0.8778       0.906548       0.904       0.90468       0.877663   \n",
      "2   MLP    0.8749       0.906548       0.904       0.90468       0.877663   \n",
      "\n",
      "   DNN Recall  DNN F1-Score  MLP Precision  MLP Recall  MLP F1-Score  \n",
      "0      0.8778      0.875762       0.876199      0.8749      0.875076  \n",
      "1      0.8778      0.875762       0.876199      0.8749      0.875076  \n",
      "2      0.8778      0.875762       0.876199      0.8749      0.875076  \n",
      "\n",
      "Final Metrics of the Committee:\n",
      "      Model  Accuracy  Precision  Recall  F1-Score\n",
      "0  Ensemble    0.9045   0.904322  0.9045  0.904302\n"
     ]
    }
   ],
   "source": [
    "#Q2C\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate metrics for individual models\n",
    "metrics_individual = {\n",
    "    \"Model\": [\"CNN\", \"DNN\", \"MLP\"],\n",
    "    \"Accuracy\": [test_acc, test_acc_dnn, test_acc_mlp]\n",
    "}\n",
    "\n",
    "# Calculate precision, recall, and F1-score for each individual model\n",
    "for model, model_name in zip([model_cnn, model_dnn, model_mlp], [\"CNN\", \"DNN\", \"MLP\"]):\n",
    "    predictions = np.argmax(model.predict(test_images), axis=1)\n",
    "    metrics_individual[model_name + \" Precision\"] = precision_score(test_labels, predictions, average='weighted')\n",
    "    metrics_individual[model_name + \" Recall\"] = recall_score(test_labels, predictions, average='weighted')\n",
    "    metrics_individual[model_name + \" F1-Score\"] = f1_score(test_labels, predictions, average='weighted')\n",
    "\n",
    "# Calculate metrics for the committee\n",
    "ensemble_predictions = np.argmax(ensemble_probabilities, axis=1)\n",
    "metrics_committee = {\n",
    "    \"Model\": [\"Ensemble\"],\n",
    "    \"Accuracy\": [test_accuracy_ensemble],\n",
    "    \"Precision\": [precision_score(test_labels, ensemble_predictions, average='weighted')],\n",
    "    \"Recall\": [recall_score(test_labels, ensemble_predictions, average='weighted')],\n",
    "    \"F1-Score\": [f1_score(test_labels, ensemble_predictions, average='weighted')]\n",
    "}\n",
    "\n",
    "print(\"\\nFinal Metrics of Individual Models:\")\n",
    "print(pd.DataFrame(metrics_individual))\n",
    "\n",
    "print(\"\\nFinal Metrics of the Committee:\")\n",
    "print(pd.DataFrame(metrics_committee))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3001d952",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Proper tabulated answers on pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
